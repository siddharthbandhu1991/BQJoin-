
#Configuring Google Cloud Data Flow Options

dataflow.job.project.id=causal-root-268810
dataflow.job.name=BQJOIN
dataflow.job.temp.location=gs://test_poc_bucket/temp/
dataflow.job.stg.location=gs://test_poc_bucket/staging/
dataflow.job.worker=2


#Configuring Source File
#dataflow.job.gcsreadfile=gs://test_poc_bucket/Sales_Records.csv
	
#Configuring PubSub Topic
#dataflow.job.pubSubTopic=beamload

#Configuring PubSub Subscriptions
#dataflow.job.pubSubSubscriptions=beamsubscriptions
	
#Configuring Big Query Table
dataflow.job.tablename1=causal-root-268810:Test.home_health_agencies_2013
dataflow.job.tablename1=dataflow.job.tablename2=causal-root-268810:Test.pubsub

#Configuring Big Query
dataflow.job.query1=SELECT * FROM [bigquery-public-data.austin_311.311_request]
dataflow.job.query2=SELECT * FROM [bigquery-public-data.austin_311.311_service_requests]

#Configuring Big Query Join Key
dataflow.job.joinkey=unique_key

#Configuring Destination File
dataflow.job.gcswritefile=gs://test_poc_bucket/Temp.csv